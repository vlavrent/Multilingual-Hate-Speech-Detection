{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilingual Hate Speech.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8+F+lZXZDWn1KHyOJD2wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6419ab084d949bd942f6abea6d16197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cafaa43d97da47e0972d9aef96a1eeb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69a8331d90f54f9da3fa4fa4362603fc",
              "IPY_MODEL_ecc469fb4b5b4b99ba4bc1c0e7f137d2",
              "IPY_MODEL_80f22332208d4b9e938389dc3f313d11"
            ]
          }
        },
        "cafaa43d97da47e0972d9aef96a1eeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69a8331d90f54f9da3fa4fa4362603fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e3f7d436d654e0290f99a40c8a77881",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10ff00d82db64b95ae059b97a35c77d7"
          }
        },
        "ecc469fb4b5b4b99ba4bc1c0e7f137d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c388f011f5a1442597cbe0ceaf489edd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 529930,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 529930,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_861ee318cc3142a0b5834fd5907fd0cc"
          }
        },
        "80f22332208d4b9e938389dc3f313d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_beab47978ff847caac86ff628080d06d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 518k/518k [00:00&lt;00:00, 1.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b7618bda43748719ecf81cd0834bd1e"
          }
        },
        "5e3f7d436d654e0290f99a40c8a77881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10ff00d82db64b95ae059b97a35c77d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c388f011f5a1442597cbe0ceaf489edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "861ee318cc3142a0b5834fd5907fd0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "beab47978ff847caac86ff628080d06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b7618bda43748719ecf81cd0834bd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d37cccf5c5b424e8f33432d84ac1e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_100f68eaa355498cbf97b9d26d2c430e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0796c90e83aa4048b4b43d660076c03a",
              "IPY_MODEL_6c142a1b0a9343b3872732b3f66b156b",
              "IPY_MODEL_80f264c85000430ba4cbbc293e90f5a9"
            ]
          }
        },
        "100f68eaa355498cbf97b9d26d2c430e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0796c90e83aa4048b4b43d660076c03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e394737535554857a0b457e56196de78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb86ab62b3b84833be30f0b8f7d01656"
          }
        },
        "6c142a1b0a9343b3872732b3f66b156b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d54126ff93564732b30c3dd2d624e21d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9155e21dc6114506b94b0c2dfe650277"
          }
        },
        "80f264c85000430ba4cbbc293e90f5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8645b7dcd99a42cdb3973b9f5e28bc8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 2.55kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6535108741784b858b967e2513ad443d"
          }
        },
        "e394737535554857a0b457e56196de78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb86ab62b3b84833be30f0b8f7d01656": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d54126ff93564732b30c3dd2d624e21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9155e21dc6114506b94b0c2dfe650277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8645b7dcd99a42cdb3973b9f5e28bc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6535108741784b858b967e2513ad443d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5db063c90c64e3682303726968a0a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5757bd1a77674fc5b58bb0a80b800e58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_514cc3d0f938414da3de9e6b078561fb",
              "IPY_MODEL_79eee1235eea4df6a7cf034f9c127473",
              "IPY_MODEL_68f71c6242674975a67ad5cb46588ef6"
            ]
          }
        },
        "5757bd1a77674fc5b58bb0a80b800e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "514cc3d0f938414da3de9e6b078561fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10d122088c0b4dfc8645ee221905fea7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df8e3345d8fc48b99b6ab48888fbef61"
          }
        },
        "79eee1235eea4df6a7cf034f9c127473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18716dc2fdf348f0a51b46bc14ce7b97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7189dda1578b49088fa9bf0b721e94c1"
          }
        },
        "68f71c6242674975a67ad5cb46588ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e2e095f6d8e40c4bd86751aced9d75c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 50.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f5d4363852840a68ae7b705a3c715e2"
          }
        },
        "10d122088c0b4dfc8645ee221905fea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df8e3345d8fc48b99b6ab48888fbef61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18716dc2fdf348f0a51b46bc14ce7b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7189dda1578b49088fa9bf0b721e94c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e2e095f6d8e40c4bd86751aced9d75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f5d4363852840a68ae7b705a3c715e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "366212a83061482b838c08fd344e319f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b6a2bbc40784cae9be2aca56ab8f91e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85b2ff27a5654bde8aa46b9a6a888157",
              "IPY_MODEL_5218dfc323cc433b8aeb7929e38f12f6",
              "IPY_MODEL_6ec13ad5d8314840a03be68669ca02ee"
            ]
          }
        },
        "3b6a2bbc40784cae9be2aca56ab8f91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85b2ff27a5654bde8aa46b9a6a888157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e98e1b47567d45d08be25e4174081813",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5c03e70c63f4deb913dad82aed56430"
          }
        },
        "5218dfc323cc433b8aeb7929e38f12f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5f98f0d5c0b4c26949230fe1c1b671a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_479ba804716f4fbfacfb253aa87164bb"
          }
        },
        "6ec13ad5d8314840a03be68669ca02ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a60d4fe9a1c34fd5804d14a9eb7c08fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 459/459 [00:00&lt;00:00, 12.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f815afa37cf644bcb0f2a875f4b8c405"
          }
        },
        "e98e1b47567d45d08be25e4174081813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5c03e70c63f4deb913dad82aed56430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5f98f0d5c0b4c26949230fe1c1b671a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "479ba804716f4fbfacfb253aa87164bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a60d4fe9a1c34fd5804d14a9eb7c08fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f815afa37cf644bcb0f2a875f4b8c405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlavrent/Multilingual-Hate-Speech-Detection/blob/main/Multilingual_Hate_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbnzyy25P6bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72db9751-1111-4c5b-994d-4c8679979606"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 508 kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3Jvc37Trg3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6959ae96-40b4-4e62-911c-0b189274e5cf"
      },
      "source": [
        "pip install sentence-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 30 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 40 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 61 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 78 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=42ef459b89b3ca8ea65b62ef3e3e6d7ae256d699c07daf97bc33c947c85af994\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.1.0 sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW98BXjgQhrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6162b747-b6dc-447c-fc1b-01a41dfbf152"
      },
      "source": [
        "pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYEUcDtQil-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5b249c-7b62-4daa-89b6-46951f601ae9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOA5DdeYQng2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38e28c9-7378-41e9-ef9b-d37000b89b4e"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "  print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7aJETliQprv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01482916-8aa9-4d89-b47e-5298914e9229"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#from torchsampler import ImbalancedDatasetSampler\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from sklearn.model_selection import KFold\n",
        "import torch, gc\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from sklearn.metrics import f1_score,classification_report\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22zIRNZwnr_O"
      },
      "source": [
        "<h1>Preprocess Polish</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOviFAICQsD0"
      },
      "source": [
        "class Polish():\n",
        "\n",
        "    def __init__(self,data_path,tag_path):\n",
        "        self.path = data_path\n",
        "        self.tag_path = tag_path\n",
        "        self.data = self.read_data()\n",
        "        self.tag = self.read_tag()\n",
        "        self.column = 'text'\n",
        "        self.label = 'label'\n",
        "\n",
        "    def read_data(self):\n",
        "\n",
        "        open_data = open(self.path, \"r\", encoding=\"utf8\")\n",
        "\n",
        "        return pd.DataFrame(open_data)\n",
        "\n",
        "    def read_tag(self):\n",
        "\n",
        "        open_tag = open(self.tag_path,'r')\n",
        "\n",
        "        return pd.DataFrame(open_tag)\n",
        "\n",
        "    def remove_punctuation(self,data,column):\n",
        "      \n",
        "      return data[column].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
        "  \n",
        "    def lower(self):\n",
        "\n",
        "        return self.data[self.column].str.lower()\n",
        "\n",
        "    def rename_columns(self,data,column):\n",
        "\n",
        "        return data.rename(columns={0:column})\n",
        "\n",
        "    def remove_mentions(self):\n",
        "\n",
        "        return self.data[self.column].apply(lambda row: re.sub(\"@[A-Za-z0-9]+_[A-Za-z0-9]+\",\"\",row))\n",
        "\n",
        "    def remove_end_line(self,data,column):\n",
        "\n",
        "        return data[column].str.replace('\\n','')\n",
        "\n",
        "    def concat(self):\n",
        "\n",
        "        self.data[self.label] = self.tag[self.label]\n",
        "\n",
        "        return self.data\n",
        "    \n",
        "    def convert_int(self):\n",
        "\n",
        "      return self.tag[self.label].apply(lambda x: int(x))\n",
        "\n",
        "\n",
        "    def clean_data(self):\n",
        "\n",
        "        text_column = self.column\n",
        "        label_column = self.label\n",
        "\n",
        "        # Rename columns in both label and text data\n",
        "        self.data = self.rename_columns(self.data,text_column)\n",
        "\n",
        "        self.tag = self.rename_columns(self.tag, label_column)\n",
        "\n",
        "        # Remove Punctuation\n",
        "        self.data[text_column] = self.remove_punctuation(self.data,text_column) \n",
        "\n",
        "        # Lower words in text data\n",
        "        self.data[text_column] = self.lower()\n",
        "\n",
        "        # Remove user mentions in text data\n",
        "        self.data[text_column] = self.remove_mentions()\n",
        "\n",
        "        # Remove end line character from label and text data\n",
        "        self.data[text_column] = self.remove_end_line(self.data,text_column)\n",
        "\n",
        "        self.tag[label_column] = self.remove_end_line(self.tag,label_column)\n",
        "\n",
        "        # Convert label to int\n",
        "        self.tag[label_column] = self.convert_int()\n",
        "        \n",
        "\n",
        "        # Concat text and labels\n",
        "\n",
        "        return self.concat()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMjctOUWn7RQ"
      },
      "source": [
        "<h1>Preprocess Slovenian</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Z5Cj8SQt7p"
      },
      "source": [
        "class Slovenian():\n",
        "    def __init__(self,path):\n",
        "        self.path = path\n",
        "        self.data = self.read_data()\n",
        "        self.column = 'text'\n",
        "        self.label = 'label'\n",
        "\n",
        "    def read_data(self):\n",
        "        return pd.read_csv(self.path)\n",
        "\n",
        "    def rename_columns(self):\n",
        "\n",
        "        self.data = self.data[['text','type']]\n",
        "        return self.data.rename(columns={'type':self.label})\n",
        "\n",
        "    def strip_punctuation(self):\n",
        "        return self.data[self.column].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
        "\n",
        "    def lower(self):\n",
        "        return self.data[self.column].str.lower()\n",
        "\n",
        "    def remove_stopwords(self, data, column):\n",
        "        data[column] = data[column].apply(lambda word: [i for i in word.split() if not i in stopwords.words(\"slovene\")])\n",
        "        return data[column].apply(lambda x: \" \".join(x))\n",
        "\n",
        "    def change_labels(self,x):\n",
        "\n",
        "        change = {'Background offensive':'offensive', 'Acceptable speech':'acceptable', 'Background violence':'offensive',\n",
        "                  'Other offensive':'offensive', 'Inappropriate':'offensive', 'Other violence':'offensive'}\n",
        "\n",
        "        for k, v in change.items():\n",
        "\n",
        "             x = x.replace(k, v)\n",
        "        return x\n",
        "\n",
        "    def convert_labels(self):\n",
        "\n",
        "        self.data[self.label] = self.data[self.label].apply(lambda x: self.change_labels(x))\n",
        "\n",
        "    def binarize_labels(self):\n",
        "\n",
        "      self.data[self.label] = self.data[self.label].apply(lambda x: 1 if x=='offensive' else 0)\n",
        "\n",
        "\n",
        "    def clean_data(self):\n",
        "\n",
        "        # Rename Columns\n",
        "        self.data = self.rename_columns()\n",
        "\n",
        "        # Strip Punctuation\n",
        "        self.data[self.column] = self.strip_punctuation()\n",
        "\n",
        "        # Lowercase\n",
        "        self.data[self.column] = self.lower()\n",
        "\n",
        "        # Remove stopwords\n",
        "        self.data[self.column] = self.remove_stopwords(self.data,self.column)\n",
        "        \n",
        "        # Convert labels\n",
        "        self.convert_labels()\n",
        "        \n",
        "        # Binarize labels\n",
        "        self.binarize_labels()\n",
        "\n",
        "        return self.data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvPd-R_5n_Pg"
      },
      "source": [
        "<h1>Preprocess Croatian</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxh_Z4cHQwxP"
      },
      "source": [
        "class Croatian():\n",
        "    def __init__(self,path):\n",
        "        self.path = path\n",
        "        self.data = self.read_data()\n",
        "        self.column = 'text'\n",
        "        self.label = 'label'\n",
        "\n",
        "    def read_data(self):\n",
        "        return pd.read_csv(self.path)\n",
        "\n",
        "    def rename_columns(self):\n",
        "\n",
        "        self.data = self.data[['text','type']]\n",
        "        return self.data.rename(columns={'type':self.label})\n",
        "\n",
        "    def strip_punctuation(self):\n",
        "        return self.data[self.column].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
        "\n",
        "    def lower(self):\n",
        "        return self.data[self.column].str.lower()\n",
        "\n",
        "    def remove_stopwords(self, data, column):\n",
        "        data[column] = data[column].apply(lambda word: [i for i in word.split() if not i in stopwords.words(\"slovene\")])\n",
        "        return data[column].apply(lambda x: \" \".join(x))\n",
        "\n",
        "    def change_labels(self,x):\n",
        "\n",
        "        change = {'Background offensive':'offensive', 'Acceptable speech':'not offensive', 'Background violence':'offensive',\n",
        "                  'Other offensive':'offensive', 'Inappropriate':'offensive', 'Other violence':'offensive'}\n",
        "\n",
        "        for k, v in change.items():\n",
        "\n",
        "             x = x.replace(k, v)\n",
        "        return x\n",
        "\n",
        "    def convert_labels(self):\n",
        "\n",
        "        self.data[self.label] = self.data[self.label].apply(lambda x: self.change_labels(x))\n",
        "\n",
        "        hate = ['offensive','not offensive']\n",
        "\n",
        "        self.data = self.data[self.data[self.label].isin(hate)]\n",
        "    \n",
        "    def binarize_labels(self):\n",
        "\n",
        "      self.data[self.label] = self.data[self.label].apply(lambda x: 1 if x=='offensive' else 0)\n",
        "\n",
        "\n",
        "    def clean_data(self):\n",
        "\n",
        "        # Rename Columns\n",
        "        self.data = self.rename_columns()\n",
        "\n",
        "        # Strip Punctuation\n",
        "        self.data[self.column] = self.strip_punctuation()\n",
        "\n",
        "        # Lowercase\n",
        "        self.data[self.column] = self.lower()\n",
        "\n",
        "        # Remove stopwords\n",
        "        self.data[self.column] = self.remove_stopwords(self.data,self.column)\n",
        "\n",
        "        self.convert_labels()\n",
        "\n",
        "        self.binarize_labels()\n",
        "\n",
        "        return self.data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-dD8ZBoFHh"
      },
      "source": [
        "<h1>Preprocess Greek</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGmn_vzx3a4X"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "class Greek():\n",
        "    def __init__(self,path):\n",
        "        self.path  = path\n",
        "        self.data = self.read_data()\n",
        "        self.column = 'text'\n",
        "        self.label = 'label'\n",
        "\n",
        "    def read_data(self):\n",
        "        return pd.read_csv(self.path)\n",
        "\n",
        "    def rename_columns(self):\n",
        "\n",
        "        return self.data.rename(columns={'tweet':self.column,'subtask_a':self.label})\n",
        "\n",
        "    def replace_hashtag(self):\n",
        "\n",
        "        return self.data[self.column].apply(lambda x: re.sub(\"#[\\w]+\",\"hashtag\",x))\n",
        "\n",
        "    def strip_punctuation(self):\n",
        "\n",
        "        return self.data[self.column].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))\n",
        "\n",
        "    def lower(self):\n",
        "        return self.data[self.column].str.lower()\n",
        "\n",
        "    def remove_stopwords(self, data, column):\n",
        "        data[column] = data[column].apply(lambda word: [i for i in word.split() if not i in stopwords.words(\"greek\")])\n",
        "        return data[column].apply(lambda x: \" \".join(x))\n",
        "\n",
        "    def binarize_labels(self):\n",
        "\n",
        "      self.data[self.label] = self.data[self.label].apply(lambda x: 0 if x=='NOT' else 1)\n",
        "\n",
        "    def clean_data(self):\n",
        "        text_column = self.column\n",
        "        label_column = self.label\n",
        "\n",
        "        # Rename Columns\n",
        "        self.data = self.rename_columns()\n",
        "\n",
        "        # Replace hashtag\n",
        "        self.data[text_column] = self.replace_hashtag()\n",
        "\n",
        "        # Strip Punctuation\n",
        "        self.data[text_column] = self.strip_punctuation()\n",
        "\n",
        "        # Lower text\n",
        "        self.data[text_column] = self.lower()\n",
        "\n",
        "        # Remove Stopwords\n",
        "        self.data[text_column] = self.remove_stopwords(self.data,text_column)\n",
        "\n",
        "        # Binarize labels\n",
        "        self.binarize_labels()\n",
        "\n",
        "        return self.data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUSbFr7LoYtM"
      },
      "source": [
        "<h1>Preprocess English</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1bH83t53oOY"
      },
      "source": [
        "class English():\n",
        "\n",
        "    def __init__(self,path):\n",
        "        self.data = self.read(path)\n",
        "        self.label = 'label'\n",
        "        self.column = 'text'\n",
        "\n",
        "    def read(self,path):\n",
        "        return pd.read_csv(path)\n",
        "\n",
        "    def replace_label(self,x):\n",
        "        if ('normal' in x) or (x==2):\n",
        "            return 'NOT'\n",
        "        else:\n",
        "            return 'HOF'\n",
        "\n",
        "    def fix_label(self):\n",
        "        self.data[self.label] = self.data[self.label].apply(lambda x: self.replace_label(x))\n",
        "\n",
        "\n",
        "    def replace_mentions(self):\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda row: re.sub(\"@[A-Za-z0-9]+_*[A-Za-z0-9]+\", \"mention\", row))\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda row: re.sub(\"mention_\", \"mention\", row))\n",
        "\n",
        "    def remove_punctuation(self):\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "\n",
        "    def replace_hashtag(self):\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda x: re.sub(\"#[\\w]+\", \"hashtag\", x))\n",
        "\n",
        "    def remove_stopwords(self):\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda word: [i for i in word.split() if not i in stopwords.words(\"english\")])\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda x: \" \".join(x))\n",
        "\n",
        "    def remove_url(self):\n",
        "        self.data[self.column] = self.data[self.column].apply(lambda x: re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '',x))\n",
        "    \n",
        "    def lower(self):\n",
        "        return self.data[self.column].str.lower()\n",
        "\n",
        "    def binarize_labels(self):\n",
        "\n",
        "      self.data[self.label] = self.data[self.label].apply(lambda x: 0 if x=='NOT' else 1)\n",
        "\n",
        "    def clean_data(self):\n",
        "        # Fix labels\n",
        "        self.fix_label()\n",
        "\n",
        "        # Remove urls\n",
        "        self.remove_url()\n",
        "\n",
        "        # Replace mentions\n",
        "        self.replace_mentions()\n",
        "\n",
        "        # Replace hashtags\n",
        "        self.replace_hashtag()\n",
        "\n",
        "        # Remove punctuation\n",
        "        self.remove_punctuation()\n",
        "\n",
        "        # Remove stopwords\n",
        "        self.remove_stopwords()\n",
        "\n",
        "        # Lower text\n",
        "        self.lower()\n",
        "\n",
        "        # Binarize labels\n",
        "        self.binarize_labels()\n",
        "\n",
        "        return self.data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbmhAi42oho8"
      },
      "source": [
        "<h1>Tokenizer, Tensors and Dataloaders</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTNquqlzQy41"
      },
      "source": [
        "class Transform_Data():\n",
        "  def __init__(self,train,test,language_model,column,label,cmodel):\n",
        "    self.max_length = 60\n",
        "    self.tokenizer = cmodel.from_pretrained(language_model)\n",
        "    self.train = train\n",
        "    self.test = test\n",
        "    self.column = column\n",
        "    self.label = label\n",
        "\n",
        "  def Tokenizer(self):\n",
        "\n",
        "    train_encodings = self.tokenizer.batch_encode_plus(self.train[self.column].tolist(),add_special_tokens = True, truncation=True, padding=True, max_length=self.max_length,return_tensors='pt')\n",
        "    train_y = torch.tensor(self.train[self.label].tolist())\n",
        "  \n",
        "    val_encodings = self.tokenizer.batch_encode_plus(self.test[self.column].tolist(),add_special_tokens = True, truncation=True, padding=True, max_length=self.max_length,return_tensors='pt')\n",
        "    val_y = torch.tensor(self.test[self.label].tolist())\n",
        "\n",
        "    return train_encodings, train_y, val_encodings,val_y \n",
        "\n",
        "  def Tensors_and_DataLoaders(self,train_encodings,train_y,val_encodings, val_y):\n",
        "\n",
        "    #====================\n",
        "    #Train data\n",
        "    #====================\n",
        "    train_data = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_y)\n",
        "    class_samples = [(train_y == 0.).sum(dim=0),(train_y == 1.).sum(dim=0)]\n",
        "    total_samples = sum(class_samples)\n",
        "    \n",
        "\n",
        "    class_weights = [total_samples/class_samples[i] for i in range(len(class_samples))]\n",
        "    weights = [class_weights[train_y[i]] for i in range(int(total_samples))]\n",
        "\n",
        "    train_sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(total_samples))\n",
        "    \n",
        "\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
        "\n",
        "\n",
        "    #====================\n",
        "    #Test/Validation data\n",
        "    #====================\n",
        "\n",
        "    val_data = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'], val_y)\n",
        "\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)\n",
        "\n",
        "    return train_dataloader, val_dataloader\n",
        "\n",
        "  def Execute(self):\n",
        "\n",
        "    train_encodings, train_y, val_encodings,val_y = self.Tokenizer()\n",
        "    train_dataloader, val_dataloader = self.Tensors_and_DataLoaders(train_encodings,train_y,val_encodings, val_y)\n",
        "    return train_encodings, train_y, val_encodings,val_y, train_dataloader, val_dataloader\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xN1Gnvqolgc"
      },
      "source": [
        "<h1>Output Layer</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFcA3kAQ58x"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Model_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, ROBERTA,freeze_bert):\n",
        "      \n",
        "      super(Model_Arch, self).__init__()\n",
        "\n",
        "      self.bert = ROBERTA\n",
        "      self.freeze_bert = freeze_bert\n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.3)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(self.bert.config.hidden_size,2)\n",
        "      \n",
        "\n",
        "      # sigmoid activation function\n",
        "      #self.sigmoid =  nn.Sigmoid()\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "      if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _,cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False) #,return_dict=False\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "      \n",
        "      # activation function\n",
        "      #x = self.relu(x)\n",
        "      \n",
        "      # dropout\n",
        "      #x = self.dropout(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      #x = self.sigmoid(x)\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffWF0qTKo3EN"
      },
      "source": [
        "<h1>Optimizer, Scheduler</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NgaShAKRFA1"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import get_scheduler\n",
        "\n",
        "\n",
        "def Optimizer_Scheduler(model,train_dataloader,num_epochs):\n",
        "  \n",
        "  optimizer = AdamW(model.parameters(), lr=5e-5) #weight_decay=0.02\n",
        " \n",
        "  num_training_steps = num_epochs * len(train_dataloader)\n",
        "  lr_scheduler = get_linear_schedule_with_warmup(\n",
        "                       optimizer=optimizer,\n",
        "                       num_warmup_steps=0,\n",
        "                       num_training_steps=num_training_steps)\n",
        "\n",
        "  return optimizer, lr_scheduler, num_training_steps"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr7ha0keo9v_"
      },
      "source": [
        "<h1>Train Model</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOj2q8iNRG7h"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def Mean(data):\n",
        "    return sum(data) / len(data)\n",
        "\n",
        "def train(model, num_epochs, train_dataloader,val_dataloader,best_f1,language,lanmodel):\n",
        "\n",
        "  # Optimizer and Scheduler\n",
        "  optimizer, lr_scheduler, num_training_steps = Optimizer_Scheduler(model,train_dataloader,num_epochs)\n",
        "\n",
        "  progress_bar = tqdm(range(num_training_steps))\n",
        "  #loss_fn = nn.BCELoss()\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "  # Initialize arrays\n",
        "  train_acc = []\n",
        "  val_acc = [] \n",
        "  train_loss = []  \n",
        "  val_loss = []\n",
        "  avg_acc_0 = []\n",
        "  avg_acc_1 = []\n",
        "  total_avg_loss_train = []\n",
        "  total_avg_loss_val = []\n",
        "\n",
        "  # Set a flag for results\n",
        "  flag = True\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "    predictions = []\n",
        "    real_label = []\n",
        "\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      batch_counts += 1\n",
        "      \n",
        "      # batch to GPU\n",
        "      batch = [r.to(device) for r in batch]\n",
        "\n",
        "      sent_id, mask, labels = batch\n",
        "      real_label.append(labels.detach().cpu().numpy())\n",
        "      \n",
        "      \n",
        "      # clear previous gradients\n",
        "      model.zero_grad()\n",
        "       \n",
        "      # predictions for current batch\n",
        "      output = model(sent_id, mask)\n",
        "\n",
        "      #pred = torch.round(output)\n",
        "      pred = torch.argmax(output,1)\n",
        "\n",
        "      pred = pred.detach().cpu().numpy()\n",
        "      pred = pred.flatten()\n",
        "      predictions.append(pred)\n",
        "\n",
        "      \n",
        "      \n",
        "      # compute loss for current batch\n",
        "      #loss = loss_fn(output, labels.unsqueeze(1).float())\n",
        "      loss = loss_fn(output, labels)\n",
        "\n",
        "      # add total loss\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "\n",
        "      # backpropagation to calculate gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # prevent the exploding gradient problem\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # update scheduler \n",
        "      lr_scheduler.step()\n",
        "\n",
        "      # clear optimizer gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      progress_bar.update(1)\n",
        "\n",
        "    # compute training loss of each batch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # flatten labels and predictions\n",
        "    flat_label = np.concatenate(real_label).astype(int).ravel().tolist()\n",
        "    \n",
        "    flat_predictions = np.concatenate(predictions).astype(int).ravel().tolist()\n",
        "\n",
        "    # Append accuracy and validation loss for training data\n",
        "    train_acc.append(f1_score(flat_label,flat_predictions))\n",
        "    train_loss.append(avg_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_flat_label,val_flat_predictions, val_avg_loss = validate(model,val_dataloader,loss_fn)\n",
        "\n",
        "    if f1_score(val_flat_label,val_flat_predictions) > best_f1:\n",
        "        best_f1 = f1_score(val_flat_label,val_flat_predictions)\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/Datasets/All/'+lanmodel+'_'+language+'_weights.pt')     \n",
        "    \n",
        "    \n",
        "    # Append accuracy and validation loss for validation data\n",
        "    val_acc.append(f1_score(val_flat_label,val_flat_predictions))\n",
        "    val_loss.append(val_avg_loss)\n",
        "\n",
        "    # Compute each class Accuracy (validation set)\n",
        "    acc_0,acc_1 = Class_F1_score(val_flat_label,val_flat_predictions)\n",
        "    avg_acc_0.append(acc_0)\n",
        "    avg_acc_1.append(acc_1)\n",
        "\n",
        "    # Print table with insights\n",
        "    if flag:\n",
        "      print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Train F1-score':^9} | {'Val F1-score':^9} | {'Class_0 F1-score':^10} | {'Class_1 F1-score':^10} \")\n",
        "      flag = False\n",
        "\n",
        "    print(\"-\"*85)\n",
        "    print(f\"{str(epoch + 1) +'/'+ str(num_epochs):^7} | {avg_loss:^12.6f} | {val_avg_loss:^10.6f} | {f1_score(flat_label,flat_predictions):^9.2f} | {f1_score(val_flat_label,val_flat_predictions):^9.2f} | {acc_0:^10.2f} | {acc_1:^10.2f} \")\n",
        "  \n",
        "  \n",
        "\n",
        "  # Print mean of Accuracy and Loss\n",
        "  print(\"-\"*85)\n",
        "  print(f\"{'Average':^7} | {Mean(train_loss):^12.6f} | {Mean(val_loss):^10.6f} | {Mean(train_acc):^9.2f} | {Mean(val_acc):^9.2f} | {Mean(avg_acc_0):^10.2f} | {Mean(avg_acc_1):^10.2f} \")\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhFSbjS1pCaP"
      },
      "source": [
        "<h1>Validate Model</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpM2TODNRJuH"
      },
      "source": [
        "def validate(model,val_dataloader,loss_fn):\n",
        "  \n",
        "    \n",
        "\n",
        "    model.eval() \n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    val_preds = []\n",
        "    val_label = []\n",
        "    \n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "      \n",
        "      batch = [t.to(device) for t in batch]\n",
        "      \n",
        "      sent_id, mask, labels = batch\n",
        "      val_label.append(labels.detach().cpu().numpy())\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        output = model(sent_id,mask)\n",
        "        \n",
        "      #loss = loss_fn(output,labels.unsqueeze(1).float())  \n",
        "      loss = loss_fn(output,labels) \n",
        "      total_loss = total_loss + loss.item()\n",
        "        \n",
        "        \n",
        "      #pred = torch.round(output)\n",
        "      pred = torch.argmax(output,1)\n",
        "      pred = pred.detach().cpu().numpy()\n",
        "      pred = pred.flatten()\n",
        "      val_preds.append(pred)\n",
        "\n",
        "    # compute training loss of each epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "    print('Total Loss: '+str(total_loss))\n",
        "    print('Avg Loss: '+str(avg_loss))\n",
        "\n",
        "    # flatten labels and predictions\n",
        "    flat_label = np.concatenate(val_label).astype(int).ravel().tolist()\n",
        "    \n",
        "    \n",
        "    flat_predictions = np.concatenate(val_preds).astype(int).ravel().tolist()\n",
        "\n",
        "    \n",
        "\n",
        "    return flat_label,flat_predictions, avg_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-rwlDQMpGHR"
      },
      "source": [
        "<h1>F1 Score per Class</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QXwxOERRLqc"
      },
      "source": [
        "def Class_F1_score(val_y,new_preds):\n",
        "\n",
        "  report = classification_report(val_y,new_preds, output_dict=True )\n",
        "\n",
        "  return report['0']['f1-score'], report['1']['f1-score']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T21KkGspP4f"
      },
      "source": [
        "<h1>Balancing with kmedoid</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcKtne5hPy1U"
      },
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import numpy as np\n",
        "import random\n",
        "from past.builtins import xrange\n",
        "\n",
        "def kMedoids(D, k, tmax=100):\n",
        "    # determine dimensions of distance matrix D\n",
        "    m, n = D.shape\n",
        "\n",
        "    if k > n:\n",
        "        raise Exception('too many medoids')\n",
        "\n",
        "    # find a set of valid initial cluster medoid indices since we\n",
        "    # can't seed different clusters with two points at the same location\n",
        "    valid_medoid_inds = set(range(n))\n",
        "    invalid_medoid_inds = set([])\n",
        "    rs,cs = np.where(D==0)\n",
        "    # the rows, cols must be shuffled because we will keep the first duplicate below\n",
        "    index_shuf = list(range(len(rs)))\n",
        "    np.random.shuffle(index_shuf)\n",
        "    rs = rs[index_shuf]\n",
        "    cs = cs[index_shuf]\n",
        "    for r,c in zip(rs,cs):\n",
        "        # if there are two points with a distance of 0...\n",
        "        # keep the first one for cluster init\n",
        "        if r < c and r not in invalid_medoid_inds:\n",
        "            invalid_medoid_inds.add(c)\n",
        "    valid_medoid_inds = list(valid_medoid_inds - invalid_medoid_inds)\n",
        "\n",
        "    if k > len(valid_medoid_inds):\n",
        "        raise Exception('too many medoids (after removing {} duplicate points)'.format(\n",
        "            len(invalid_medoid_inds)))\n",
        "\n",
        "    # randomly initialize an array of k medoid indices\n",
        "    M = np.array(valid_medoid_inds)\n",
        "    np.random.shuffle(M)\n",
        "    M = np.sort(M[:k])\n",
        "\n",
        "    # create a copy of the array of medoid indices\n",
        "    Mnew = np.copy(M)\n",
        "\n",
        "    # initialize a dictionary to represent clusters\n",
        "    C = {}\n",
        "    for t in xrange(tmax):\n",
        "        # determine clusters, i. e. arrays of data indices\n",
        "        J = np.argmin(D[:,M], axis=1)\n",
        "        for kappa in range(k):\n",
        "            C[kappa] = np.where(J==kappa)[0]\n",
        "        # update cluster medoids\n",
        "        for kappa in range(k):\n",
        "            J = np.mean(D[np.ix_(C[kappa],C[kappa])],axis=1)\n",
        "            j = np.argmin(J)\n",
        "            Mnew[kappa] = C[kappa][j]\n",
        "        np.sort(Mnew)\n",
        "        # check for convergence\n",
        "        if np.array_equal(M, Mnew):\n",
        "            break\n",
        "        M = np.copy(Mnew)\n",
        "    else:\n",
        "        # final update of cluster memberships\n",
        "        J = np.argmin(D[:,M], axis=1)\n",
        "        for kappa in range(k):\n",
        "            C[kappa] = np.where(J==kappa)[0]\n",
        "\n",
        "    # return results\n",
        "    return M, C\n",
        "\n",
        "def balance(data,sample):\n",
        "      model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
        "      embeddings = model.encode(data['text'].to_numpy())\n",
        "\n",
        "      D = pairwise_distances(embeddings, metric='cosine')\n",
        "\n",
        "      M, C = kMedoids(D, sample)\n",
        "      return data.iloc[M]\n",
        "\n",
        "def execute(data,sample):\n",
        "   \n",
        "    return balance(data,sample)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7QOp-rdpeWJ"
      },
      "source": [
        "<h1>Choose dataset for Training</h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F54V2TyR3HA"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def find_length(language):\n",
        "  length = []\n",
        "  \n",
        "  for count, value in enumerate(language):\n",
        "    \n",
        "    if value=='slovenian' or value=='Slovenian':\n",
        "      # Slovenian\n",
        "      text_path = \"/content/drive/My Drive/Datasets/Slovenian/Slovene_train_set.csv\"\n",
        "      length.append(len(pd.read_csv(text_path).index))\n",
        "\n",
        "    elif value=='polish' or value=='Polish':\n",
        "      # Polish\n",
        "      text_path = \"/content/drive/My Drive/Datasets/Polish/training_set_clean_only_text.txt\"\n",
        "      tag_path = \"/content/drive/My Drive/Datasets/Polish/training_set_clean_only_tags.txt\"\n",
        "      length.append(len(pd.read_csv(open(tag_path, \"r\", encoding=\"utf8\")).index))\n",
        "      \n",
        "    elif value=='croatian' or value=='Croatian':\n",
        "      # Croatian\n",
        "      text_path = \"/content/drive/My Drive/Datasets/Croatian/Croatian_train_set.csv\"\n",
        "      length.append(len(pd.read_csv(text_path).index))\n",
        "\n",
        "    elif value=='greek' or value=='Greek':\n",
        "      # Greek\n",
        "      text_path = \"/content/drive/My Drive/Datasets/Greek/offenseval-gr_train.csv\"\n",
        "      \n",
        "      length.append(len(pd.read_csv(text_path).index))\n",
        "  return min(length)\n",
        " \n",
        "\n",
        "\n",
        "def preprocess_language(language,length,number_language):\n",
        "\n",
        "  if language=='slovenian' or language=='Slovenian':\n",
        "    # Slovenian\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Slovenian/Slovene_train_set.csv\"\n",
        "\n",
        "    slovenian = Slovenian(text_path)\n",
        "    data = slovenian.clean_data()\n",
        "\n",
        "  elif language=='polish' or language=='Polish':\n",
        "    # Polish\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Polish/training_set_clean_only_text.txt\"\n",
        "    tag_path = \"/content/drive/My Drive/Datasets/Polish/training_set_clean_only_tags.txt\"\n",
        "\n",
        "    polish = Polish(text_path,tag_path)\n",
        "    data = polish.clean_data()\n",
        "    if number_language>1 and len(data)>length:\n",
        "          data  = execute(data,length)\n",
        "  \n",
        "  elif language=='croatian' or language=='Croatian':\n",
        "    # Croatian\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Croatian/Croatian_train_set.csv\"\n",
        "\n",
        "    croatian = Croatian(text_path)\n",
        "    data = croatian.clean_data()\n",
        "    if number_language>1 and len(data)>length:\n",
        "          data  = execute(data,length)\n",
        "\n",
        "  elif language=='greek' or language=='Greek':\n",
        "    # Greek\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Greek/offenseval-gr_train.csv\"\n",
        "\n",
        "    greek = Greek(text_path)\n",
        "    data = greek.clean_data()\n",
        "    if number_language>1 and len(data)>length:\n",
        "      data  = execute(data,length)\n",
        "  elif language=='english' or language=='English':\n",
        "    # English\n",
        "    text_path = \"/content/drive/My Drive/Datasets/English/English_train_set.csv\"\n",
        "\n",
        "    english = English(text_path)\n",
        "    data = english.clean_data()\n",
        "    if number_language>1 and len(data)>length:\n",
        "      data  = execute(data,length)\n",
        "  return data\n",
        "\n",
        "def languages(lang):\n",
        "  \n",
        "  total_languages = []\n",
        "  length = find_length(lang)\n",
        "  print(len(lang))\n",
        "  \n",
        "\n",
        "  for count, value in enumerate(lang):\n",
        "    \n",
        "    total_languages.append(preprocess_language(value,length,len(lang)))\n",
        "  \n",
        "  return pd.concat(total_languages)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuaLEg1PiUcy"
      },
      "source": [
        "<h1>Choose Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rMrGRiMRTe8"
      },
      "source": [
        "def choose_model(cmodel):\n",
        "  if cmodel=='Bert' or cmodel=='BERT' or cmodel=='BERT' or 'bert':\n",
        "    return BertModel, BertTokenizer\n",
        "  elif cmodel=='ROBERTA' or cmodel=='XLMRoberta' or cmodel=='Roberta' or cmodel=='roberta':\n",
        "    return XLMRobertaModel, XLMRobertaTokenizer"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H9ChVChiQHA"
      },
      "source": [
        "<h1>Language Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKqYIm9iPon"
      },
      "source": [
        "def language_model(mlang):\n",
        "\n",
        "  if mlang=='multilingual_roberta':\n",
        "    return \"xlm-roberta-base\"\n",
        "\n",
        "  elif mlang=='bert_greek':\n",
        "    return \"nlpaueb/bert-base-greek-uncased-v1\"\n",
        "\n",
        "  elif mlang=='bert_polish':\n",
        "    return \"dkleczek/bert-base-polish-uncased-v1\"\n",
        "  \n",
        "  elif mlang=='bert_croatian':\n",
        "    return \"EMBEDDIA/crosloengual-bert\"\n",
        "  \n",
        "  elif mlang=='bert_slovenian':\n",
        "    return \"EMBEDDIA/sloberta\"\n",
        "  \n",
        "  elif mlang=='multilingual_bert':\n",
        "    return \"bert-base-multilingual-cased\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwWMDhDUiclD"
      },
      "source": [
        "<h1>Model Settings</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeZbQl5-Tk9B"
      },
      "source": [
        "settings = {\n",
        "    'language_model':'bert_greek', #multilingual_roberta, multilingual_bert, bert_greek, bert_polish, bert_croatian, bert_slovenian\n",
        "    'model': 'bert',                #roberta, bert\n",
        "    'num_epochs': 5,\n",
        "    'training_language': ['greek'] #greek, english, slovenian, polish, croatian\n",
        "}\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktU2C51upy6K"
      },
      "source": [
        "<h1>Execute </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pksc5Y_R6h-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525,
          "referenced_widgets": [
            "d6419ab084d949bd942f6abea6d16197",
            "cafaa43d97da47e0972d9aef96a1eeb6",
            "69a8331d90f54f9da3fa4fa4362603fc",
            "ecc469fb4b5b4b99ba4bc1c0e7f137d2",
            "80f22332208d4b9e938389dc3f313d11",
            "5e3f7d436d654e0290f99a40c8a77881",
            "10ff00d82db64b95ae059b97a35c77d7",
            "c388f011f5a1442597cbe0ceaf489edd",
            "861ee318cc3142a0b5834fd5907fd0cc",
            "beab47978ff847caac86ff628080d06d",
            "1b7618bda43748719ecf81cd0834bd1e",
            "3d37cccf5c5b424e8f33432d84ac1e69",
            "100f68eaa355498cbf97b9d26d2c430e",
            "0796c90e83aa4048b4b43d660076c03a",
            "6c142a1b0a9343b3872732b3f66b156b",
            "80f264c85000430ba4cbbc293e90f5a9",
            "e394737535554857a0b457e56196de78",
            "cb86ab62b3b84833be30f0b8f7d01656",
            "d54126ff93564732b30c3dd2d624e21d",
            "9155e21dc6114506b94b0c2dfe650277",
            "8645b7dcd99a42cdb3973b9f5e28bc8c",
            "6535108741784b858b967e2513ad443d",
            "d5db063c90c64e3682303726968a0a4f",
            "5757bd1a77674fc5b58bb0a80b800e58",
            "514cc3d0f938414da3de9e6b078561fb",
            "79eee1235eea4df6a7cf034f9c127473",
            "68f71c6242674975a67ad5cb46588ef6",
            "10d122088c0b4dfc8645ee221905fea7",
            "df8e3345d8fc48b99b6ab48888fbef61",
            "18716dc2fdf348f0a51b46bc14ce7b97",
            "7189dda1578b49088fa9bf0b721e94c1",
            "3e2e095f6d8e40c4bd86751aced9d75c",
            "1f5d4363852840a68ae7b705a3c715e2",
            "366212a83061482b838c08fd344e319f",
            "3b6a2bbc40784cae9be2aca56ab8f91e",
            "85b2ff27a5654bde8aa46b9a6a888157",
            "5218dfc323cc433b8aeb7929e38f12f6",
            "6ec13ad5d8314840a03be68669ca02ee",
            "e98e1b47567d45d08be25e4174081813",
            "a5c03e70c63f4deb913dad82aed56430",
            "a5f98f0d5c0b4c26949230fe1c1b671a",
            "479ba804716f4fbfacfb253aa87164bb",
            "a60d4fe9a1c34fd5804d14a9eb7c08fa",
            "f815afa37cf644bcb0f2a875f4b8c405"
          ]
        },
        "outputId": "09f6f918-d41b-4d01-fba2-75cfb8ae3864"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Concat data\n",
        "data = languages(settings['training_language'])\n",
        "\n",
        "# Choose Language Model\n",
        "lang_model = language_model(settings['language_model'])\n",
        "\n",
        "# Choose model\n",
        "cmodel,ctokenizer = choose_model(settings['model'])\n",
        "\n",
        "# Train Test split\n",
        "train_dataset,val_dataset = train_test_split(data,test_size=0.15,random_state=21)\n",
        "  \n",
        "# Transfom Data\n",
        "transform = Transform_Data(train_dataset,val_dataset,lang_model,'text','label',ctokenizer)\n",
        "train_encodings, train_y, val_encodings,val_y, train_dataloader, val_dataloader = transform.Execute()\n",
        "\n",
        "# Initiate Model\n",
        "\n",
        "model_arch = cmodel.from_pretrained(lang_model)\n",
        "model = Model_Arch(model_arch,False)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Train Model\n",
        "language = settings['training_language']\n",
        "language = '_'.join(language)\n",
        "lanmodel = settings['model']\n",
        "\n",
        "train(model, settings['num_epochs'], train_dataloader,val_dataloader,0,language,lanmodel)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6419ab084d949bd942f6abea6d16197",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/518k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d37cccf5c5b424e8f33432d84ac1e69",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5db063c90c64e3682303726968a0a4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "366212a83061482b838c08fd344e319f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-31c03ce7826a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Transfom Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransform_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mctokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Initiate Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-62579eb44689>\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensors_and_DataLoaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_encodings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-62579eb44689>\u001b[0m in \u001b[0;36mTokenizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_special_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2627\u001b[0m         )\n\u001b[1;32m   2628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m             ]\n\u001b[1;32m    506\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescaped_special_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\")|\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"(.+?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    505\u001b[0m             ]\n\u001b[1;32m    506\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"(\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"|\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mescaped_special_toks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\")|\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mr\"(.+?)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIScla6Up9vl"
      },
      "source": [
        "<h1>Predict class</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJm2GqZSLre"
      },
      "source": [
        "def predict(model, test_dataloader):\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # File in drive\n",
        "    path = '/content/drive/My Drive/Datasets/All/bert_greek_weights.pt'\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "            #preds = logits.detach().cpu().numpy()\n",
        "            \n",
        "        all_logits.append(torch.round(logits))\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    preds = all_logits.detach().cpu().numpy()\n",
        "    preds = np.concatenate(preds).astype(int).ravel().tolist()\n",
        "    \n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    #probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoKHNHjuqTyN"
      },
      "source": [
        "<h1>Choose Language</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gchdhaUgkbDx"
      },
      "source": [
        "def choose_language(clanguage):\n",
        "\n",
        "  if clanguage=='Slovenian' or clanguage=='slovenian':\n",
        "    # Test path Slovenian\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Slovenian/Slovene_test_set.csv\"\n",
        "    \n",
        "    # Clean Slovenian data\n",
        "    slovenian = Slovenian(text_path)\n",
        "    test_data = slovenian.clean_data()\n",
        "\n",
        "  elif clanguage=='Polish' or clanguage=='polish':\n",
        "    # Text path Polish\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Polish/test_set_clean_only_text.txt\"\n",
        "    tag_path = \"/content/drive/My Drive/Datasets/Polish/test_set_clean_only_tags.txt\"\n",
        "    \n",
        "    # Clean Polish data\n",
        "    polish = Polish(text_path,tag_path)\n",
        "    test_data = polish.clean_data()\n",
        "\n",
        "  elif clanguage=='Croatian' or clanguage=='croatian':\n",
        "    # Text path Croatian\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Croatian/Croatian_test_set.csv\"\n",
        "    \n",
        "    # Clean Croatian Data\n",
        "    croatian = Croatian(text_path)\n",
        "    test_data = croatian.clean_data()\n",
        "  \n",
        "  elif clanguage=='Greek' or clanguage=='greek':\n",
        "    # Text path Greek\n",
        "    text_path = \"/content/drive/My Drive/Datasets/Greek/offenseval-gr-test.csv\"\n",
        "    \n",
        "    # Clean data\n",
        "    greek = Greek(text_path)\n",
        "    test_data = greek.clean_data()\n",
        "\n",
        "  return test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suDEh2uNqYEn"
      },
      "source": [
        "<h1>Make Predictions</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r1917d8SMSp"
      },
      "source": [
        "import numpy\n",
        "import torch, gc\n",
        "\n",
        "\n",
        "# Choose Testing dataset\n",
        "test_data = choose_language('greek')\n",
        "\n",
        "lang_model = language_model(settings['language_model'])\n",
        "cmodel,ctokenizer = choose_model(settings['model'])\n",
        "\n",
        "# Tokenize and Encode Data\n",
        "tokenizer = ctokenizer.from_pretrained(lang_model)\n",
        "test_encodings = tokenizer.batch_encode_plus(test_data['text'].tolist(),add_special_tokens = True, truncation=True, padding=True, max_length=60,return_tensors='pt')\n",
        "\n",
        "# Convert input_ids and attention_mask to tensors\n",
        "test_seq = torch.tensor(test_encodings['input_ids'])\n",
        "test_mask = torch.tensor(test_encodings['attention_mask'])\n",
        "\n",
        "# Sample data\n",
        "test_dataset = TensorDataset(test_seq, test_mask)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "test_y = torch.tensor(test_data['label'].tolist())\n",
        "\n",
        "# Model\n",
        "bert = cmodel.from_pretrained(lang_model)\n",
        "model = Model_Arch(bert,False)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "# Predict\n",
        "test_pred = predict(model, test_dataloader)\n",
        "test_label = test_y.detach().cpu().numpy()\n",
        "\n",
        "# Print Results\n",
        "print(test_label)\n",
        "print(len(test_label))\n",
        "print(len(test_pred))\n",
        "print(classification_report(test_label,test_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODa11uioE6SE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}